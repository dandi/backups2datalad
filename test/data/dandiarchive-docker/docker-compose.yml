# Based on <https://github.com/dandi/dandi-cli/blob/master/dandi/tests/data/dandiarchive-docker/docker-compose.yml>

services:
  django:
    image: dandiarchive/dandiarchive-api
    command: ["./manage.py", "runserver", "--nothreading", "0.0.0.0:8000"]
    # Log printing via Rich is enhanced by a TTY
    tty: true
    depends_on:
      minio:
        condition: service_healthy
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_started
    environment: &django_env
      DJANGO_SETTINGS_MODULE: dandiapi.settings.development
      DJANGO_DATABASE_URL: postgres://postgres:postgres@postgres:5432/django
      DJANGO_CELERY_BROKER_URL: amqp://rabbitmq:5672/
      # The Minio URL needs to use 127.0.0.1 instead of localhost so that blob
      # assets' "S3 URLs" will use 127.0.0.1, and thus tests that try to open
      # these URLs via fsspec will not fail on systems where localhost is both
      # 127.0.0.1 and ::1.
      DJANGO_MINIO_STORAGE_URL: http://minioAccessKey:minioSecretKey@minio:9000/dandi-dandisets
      DJANGO_MINIO_STORAGE_MEDIA_URL: http://127.0.0.1:9000/dandi-dandisets
      # When in Docker, the bridge network sends requests from the host machine exclusively via a
      # dedicated IP address. Since there's no way to determine the real origin address,
      # consider any IP address (though actually this will only be the single dedicated address) to
      # be internal. This relies on the host to set up appropriate firewalls for Docker, to prevent
      # access from non-internal addresses.
      DJANGO_INTERNAL_IPS: 0.0.0.0/0
      DJANGO_DANDI_WEB_APP_URL: http://localhost:8085
      DJANGO_DANDI_API_URL: http://localhost:8000
      DJANGO_DANDI_JUPYTERHUB_URL: https://hub.dandiarchive.org
    ports:
      - "127.0.0.1:8000:8000"

  celery:
    image: dandiarchive/dandiarchive-api
    command: [
      "uv",
      "run",
      "celery",
      "--app", "dandiapi.celery",
      "worker",
      "--loglevel", "INFO",
      "--without-heartbeat",
      "-Q","celery,calculate_sha256,ingest_zarr_archive,manifest-worker",
      "-c","1",
      "-B"
    ]
    # Docker Compose does not set the TTY width, which causes Celery errors
    tty: false
    depends_on:
      minio:
        condition: service_healthy
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_started
    environment:
      << : *django_env
      DJANGO_DANDI_VALIDATION_JOB_INTERVAL: "5"

  minio:
    image: minio/minio:latest
    # When run with a TTY, minio prints credentials on startup
    tty: true
    command: ["server", "/data"]
    ports:
      - "127.0.0.1:9000:9000"
    expose:
      - "9001"  # for minio console access
    environment:
      MINIO_ROOT_USER: minioAccessKey
      MINIO_ROOT_PASSWORD: minioSecretKey
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 1s
      timeout: 10s
      retries: 10

  createbuckets:
    image: minio/mc:latest
    environment:
      MINIO_ACCESS_KEY: minioAccessKey
      MINIO_SECRET_KEY: minioSecretKey
    depends_on:
      minio:
        condition: service_healthy
    # No, changing this to `entrypoint: mc alias ...` will not work, as Docker
    # Compose splits string entrypoints using shell syntax but without actual
    # support for `&&`.
    entrypoint: >
      sh -c "mc alias set myminio http://minio:9000 minioAccessKey minioSecretKey
      && mc mb myminio/dandi-dandisets --with-versioning
      && mc version enable myminio/dandi-dandisets
      && mc anonymous set public myminio/dandi-dandisets"

  postgres:
    environment:
      POSTGRES_DB: django
      POSTGRES_PASSWORD: postgres
    image: postgres
    expose:
      - "5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres"]
      interval: 7s
      timeout: 3s
      retries: 5

  rabbitmq:
    image: rabbitmq:management
    expose:
      - "5672"
